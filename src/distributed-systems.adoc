= Distributed systems

A distributed system is a computer system whose components are located on lots
of different computers, which communicate and coordinate their actions by
passing messages between themselves over a network.

An individual computer program that runs within a distributed system is called
a *distributed program*, and *distributed programming* is the process of
developing and maintaining such programs. The term *distributed computing* can
refer to distributed systems and also to the field of computer science that
studies them.

Examples of distributed systems include service-oriented architecture (SOA)
systems, massively multiplayer online games, and peer-to-peer applications.
Message passing systems include HTTP, RPC-like connectors, and message queues.

== Designing distributed systems

Distributed computing is hard.

As soon as you distribute processing and data, you add a huge amount of
complexity and many more ways that things can go wrong. Distributed systems are
inherently more complex than single-node systems (aka. monoliths) and they
require a different set of design principles and systems thinking.

Distributed computing should be avoided until it is required to solve specific
problems, such as *link:./scalability.adoc[scalability]* or
*link:./fault-tolerance.adoc[fault tolerance]*. Better to start with a
[modular monolith], with scalability planned into the design from the start, and
extract independent services incrementally as and when required.

Reasoning about *link:./concurrency.adoc[concurrency]* and building for
*link:./fault-tolerance.adoc[fault tolerance]* are probably the two hardest
things in distributed *link:./system-design.adoc[systems design]*.

Distributed systems are inherently unreliable. They are subject to a wide range
of failures, including network partitions, delayed messages, and node crashes.
The principle of *designing for failure* means designing each service in a way
that it can tolerate failures in dependent services. Fault tolerance is a key
*link:./quality-attributes.adoc[quality attribute]* in distributed systems,
and needs to be treated as a first-class concern in the
*link:./system-design.adoc[system design]*.

And because distributed systems generally use asynchronous communication
between services, managing concurrency and ensuring
*link:./consistency.adoc[eventual consistency]* are also key design
concerns.

== Trade-offs in distributed systems

*link:./cap-theorem.adoc[CAP theorem]* is a key concept in distributed systems.
It states that in the presence of a network partition, you have to choose
between *link:./consistency.adoc[consistency]* and
*link:availability.adoc[availability]*. You can't have both.

''''

.Related links
****
* link:https://www.researchgate.net/publication/322500050_Fallacies_of_Distributed_Computing_Explained[Fallacies of distributed computing explained], Arnon Rotem-Gal-Oz, Doctor Dobbs Journal (2008)

* link:https://architecturenotes.co/fallacies-of-distributed-systems/[Fallacies of distributed systems], Architecture Notes (2022)

* link:http://www.allthingsdistributed.com/2008/12/eventually_consistent.html[Eventually consistent - revisited], Werner Vogels
****
