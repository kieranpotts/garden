= Concurrency

Concurrency refers to the ability of a computer system to handle multiple tasks at the same time.
This is achieved by interleaving the execution of processes on a single processing unit (CPU)
through context switching. This creates the illusion of parallelism, but in reality the tasks are
not processes simultaneously. Instead, the CPU switches between tasks, giving each a slice of time
to execute.

A concurrent program uses a single CPU core but switches between tasks (ie. threads) to make the
most efficient use of CPU time. This contrasts to a *link:./parallel-computing.adoc[parallel program]*,
which uses multiple CPU cores, each performing a task independently. Programs may have both concurrent
and parallel characteristics, or neither.

----
Parallelism
  CPU core 1 -----------------------> Task 1
  CPU core 2 -----------------------> Task 2

Concurrency
  CPU core 1 -----       ----->       Task 1
                  -------      -----> Task 2
----

Parallel program is true "multi-tasking", meaning tasks are literally processed "at the same time".
Concurrency is "multi-threading", meaning that independent tasks are sharing the same execution
thread while appearing to be processed simultaneously.

Concurrency can be useful for improving the responsiveness of a system, by allowing it to handle
multiple tasks without waiting for one to complete before starting another. It is commonly used in
scenarios where tasks involve waiting for input/output operations, such as reading from a file or
waiting for user output.

For example, consider a text editor where you can continue to type while the document is being
saved. The document update and save operations are separate, and handled concurrently.

.Asynchronous operations
****
The term "asynchronous" can mean different things in different contexts. In general, in computer
science the term "asynchronous" refers to two or more events that do not happen at the same time,
ie. they are not synchronous.

In computer programs, concurrency and parallelism are different solutions to achieving asynchronous
operations. Sometimes, the operations are not truly asynchronous at all, but are really _deferred_
operations â€“ they are handled by the main thread but only after the program has returned its
response to the user or client.

In JavaScript, for example, `async` operations are concurrent ones that are implemented using
promise-based APIs. They are ideal for waiting on input or responses from external systems or users,
without blocking other processing on the main thread in the meantime.

"Asynchronous communication" is a different concept, and it refers to any method of exchanging
messages in which the sending, receiving, and processing of each message is not dependent upon the
sending, receipt, or processing of other messages. For example, messages may be sent without waiting
for a response or even acknowledgement, and receivers may process messages after they have been
received, and perhaps in any order.

Email is the classic example of asynchronous communication.
****
